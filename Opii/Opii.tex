\documentclass[a4paper, 12pt]{article}

\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb}
\usepackage[explicit]{titlesec}
\usepackage{ulem}
\usepackage[onehalfspacing]{setspace}
\usepackage{algpseudocode}

\titleformat{\subsection}
{\small}{\thesubsection}{1em}{\uline{#1}}
\begin{document}
	\begin{titlepage} 
		\title{Opii summary}
		\clearpage\maketitle
		\thispagestyle{empty}
	\end{titlepage}
	\tableofcontents
	\section{Introduction}
	\subsection{Turing Machine}
	\textbf{Definition} (alphabet)\\
	An alphabet $A$ is a set containing at least two symbols excluding $\sqcup$. $A^n$ is the set of all words with length $n$ over $A$. By convention $A^0 = \{\sqcup\}$. Additionally \[A^* = \bigcup_{n \in \mathbb{N}_0} A^n\] A language $L$ is a subset of $A^*$. A word is an element of $L$.\\
	\textbf{Definition} (Turing machine)\\
	Let $\overline{A} = A \cup \{\sqcup\}$. A Turing machine is a function \[\phi : \underbrace{\{0,...,N\}}_{\text{state}} \times \underbrace{\overline{A}}_{\text{symbol}} \to \underbrace{\{-1, 0, ..., N\}}_{\text{new state}} \times \underbrace{\overline{A}}_{\text{new symbol}} \times \underbrace{\{-1, 0, 1\}}_{\text{left, stay, right}}\]
	for any $N \geq 0$.\\
	The computation of $\phi$ for input $x \in A^*$ is a sequence of triplets \[(n^{(i)}, s^{(i)}, \pi^{(i)})\]
	for some $i \in \mathbb{N}_0$ with \begin{itemize}
		\item $n^{(i)} \in \{-1, 0, ..., N\}$
		\item $s^{(i)} \in \overline{A}^\mathbb{Z}$
		\item $\pi^{(i)} \in \mathbb{Z}$ 
	\end{itemize}
	For $i = 0$ we have:\begin{itemize}
		\item $n^0 = 0$ (initial state)
		\item $s_j^0 = \begin{cases}
			x_j, & 1\leq j \leq length(x)\\
			\sqcup, & j \leq 0, \text{ or } j\geq length(x)+1
		\end{cases}$
		\item $\pi^0 = 1$
	\end{itemize} 
	if $n^{(i)} = -1$, the computation ends. We set $time(\phi, x) := i$ and $output(\phi, x) := (s_1^{(i)}, ..., s_k^{(i)})$ where $k = \min\{j \in \mathbb{N}_0 : s_j^{(i)} = \sqcup\} -1$.\\
	\textbf{Definition} (computational problem)\\
	A pair $(X, R)$ where $X\subset A^*$ is a language and $R\subset X \times A^*$ is a relation such that $\forall x \in X: \; \exists y \in A^*$ with $(x,y) \in R$ is called a computational problem. $\phi$ solves a problem if $time(\phi, x) < \infty$ and $(x, output(\phi, x)) \in R$. If $time(\phi, x) < p(length(x))$ for a $p \in \mathbb{P}_n$ then $\phi$ is a polynomial turing machine.
	
	\section{Complexity and NP-completeness}
	\textbf{Definition} (Decision problem, class P)\\
	A decision problem $P$ is a pair $(X,Y)$ where $X$ is a language that is decidable in polynomial time and $Y\subseteq X$. The elements of $Y$ are \underline{yes-instances} of $P$ and the elements of $X\setminus Y$ are \underline{no-instances} of $P$. An algorithm for $P$ (a Turing machine) computes the function $f: X\to \{0,1\}$ where $f(x) = 1$ iff $x \in Y$. If there is an algorithm for $P$ that works in polynomial time, $P$ belongs to the class \textbf{P}.\\
	\textbf{Definition} (NP and CO-NP classes)\\
	A problem $P = (X,Y)$ belongs to \textbf{NP} if there is a polynomial $p$ and a decision problem $P' = (X',Y')$ in \textbf{P} where \[X' = \{x\# c \;|\; x \in X \text{ and } c \in \{0,1\}^{\lfloor p(size(x))\rfloor}\}\]
	such that \[Y = \{x \in X \; |\; \exists c \in \{0,1\}^{\lfloor p(size(x))\rfloor} \text{ s.t. } x\#c \in Y'\}\]
	The string $c$ is a certificate for $x$. An algorithm for $P'$ checks the certificate. A problem belongs to \textbf{co-NP} iff $(X, X\setminus Y)$ is in \textbf{P}.\\
	\textbf{Theorem}
	\begin{itemize}
		\item $P \subseteq NP \;\cap\; co-NP$
		\item \texttt{Hamiltonian cycle} is in $NP$.
		\item \texttt{Integer linear inequalities} is in $NP$.
	\end{itemize}
	\textbf{Definition} (NP-completeness)\\
	A decision problem $P_1 = (X_1, Y_1)$ can be polynomially transformed to a decision problem $P_2 = (X_2,Y_2)$ if $\exists f: X_1 \to X_2$ computable in polynomial time s.t. \[f(x) \in Y_2 \Leftrightarrow x \in Y_1 \; \forall x \in X_1\]
	A problem $P$ is \textbf{NP-complete} if all problems in \textbf{NP} can be transformed to $P$.
	\subsection{Boolean Formulas}
	We focus on formulas in conjunctive form (KNF). $n$-SAT is defined as the problem to find values for each literal s.t. the formula evaluates to true. Each clause has $n$ literals.\\
	Let $x_1,...,x_n$ be variables, $x_i \in \{0,1\}$. We write $\overline{x_i}$ for a negative literal. For a formula in disjunctive form (DNF) an assignment that evaluates to true can always be found in polynomial time regardless of $n$.\\
	\textbf{Theorem}\\
	\texttt{2-SAT} $\in$ \textbf{P}.\\
	\underline{Proof}\\
	Let $f$ be given as CNF. First, we can remove all clauses of length one by assigning the variable true or false so that this clause evaluates to true. Additionally, no subformula of the form $x_i \land \overline{x_i}$ can exist, because these set $f$ to false immediately. We construct a digraph $D$ with vertices $V(D) = \{x_1,...,x_n\} \cup \{\overline{x_1},...,\overline{x_n}\}$. The edges $(\overline{x}, y)$ and $(\overline{y}, x)$ correspond to $\overline{x} \implies y$ and $\overline{y} \implies x$ for a clause $(x\lor y)$. Now, we identify the strong components of $D$, $D_1,...,D_c$ which are the maximal components such that all pairs $(u,v)$ in $D_i$ are connected by a $u-v$-path and a $v-u$-path in $D_i$. Finding $D_1,...,D_c$ can be done in polynomial time. By contracting each $D_i$ to a node $u_i$ we get a new acyclic graph $\overset{\sim}{D}$ with a topological order: If $u_1,...,u_k$ is a topological order, then there is no arc $(u_j,u_i)$ with $j>i$.\\
	We claim the following: $f$ is satisfiable iff no strong component has a variable $x_i$ and its negation $\overline{x_i}$.\\
	$\Rightarrow$: if both belong to a strong component, $x$ can't be set to true nor false, the statement follows.\\
	$\Leftarrow$: Suppose $x_i \in D_r$ and $\overline{x_i} \in D_s$. If $r<s$ in the topological set $x_i = 0$ and vice versa.\\
	\textbf{Theorem}\\
	\texttt{3-SAT} $\in$ \textbf{NPC}\\
	\underline{Proof}\\
	Since we can check any assignement of truth values in polynomial time, it is obvious that \texttt{3-SAT} is in \textbf{NP}. Since we already know that \texttt{Satisfiability} is in \textbf{NPC} we construct a transformation from a formula $f_{SAT}$ to $f_{3SAT}$.\\
	Let $f_{SAT} = C_1 \land ... \land C_m$. \begin{itemize}
		\item if $\left|C_i\right| = 3$ we can leave this clause in $f_{3SAT}$.
		\item if $\left|C_i\right| \geq 4$ we introduce $k-3$ variables $y_1,...,y_{k-3}$ and $k-2$ clauses \[(x_1 \lor x_2 \lor y_1) \land (\overline{y_1} \lor x_3 \lor y_2) \land ... \land (\overline{y_{k-4}} \lor x_{k-2} \lor y_{k-3}) \land (\overline{y_{k-3}} \lor x_{k-1} \lor x_k)\]
		Note that: \begin{itemize}
			\item{} If the assignment for $x_i$ makes $(x_1 \lor ... \lor x_n)$ true, then each if the $k-2$ clauses will be true.
			\item If all $k-2$ clauses are true, then $(x_1 \lor ... \lor x_n)$ will be true.
		\end{itemize} 
	\item if the clause is $(x_1\lor x_2)$ then create two clauses $(x_1 \lor x_2 \lor y)$ and $(x_1 \lor x_2 \lor \overline{y})$.
	\item if $C_i = (x_1)$ then create four clauses with all possible assignments of $y_1$ and $y_2$.
	\end{itemize}
	By construction $f_{SAT}$ is satisfiable iff $f_{3SAT}$ is satisfiable and the transformation can be done in polynomial time.\\
	\textbf{Problem} (\texttt{independent set})\\
	\underline{Input}: A graph $G$ and an integer $k \leq n(G)$\\
	\underline{Question}: Does $G$ have an independent set (set of non-neighbouring nodes) of order at least $k$?\\
	\textbf{Theorem}\\
	\texttt{Independent Set} $\in$ \textbf{NPC}.

	\section{Optimization problems}
	\subsection{Introduction}
	\textbf{Definition}\\
	An optimization problem $P$ is a 4-tuple $(X, (S_x)_{x\in X}, c, \text{goal})$ where \begin{itemize}
		\item $X$ is a language over $\{0,1\}$that is decidable in polynomial time\item there is a polynomial $p$ s.t. $\forall x \in X$ \begin{itemize}
			\item $S_x$ is a subset if $\{0,1\}^*$
			\item $\left|y\right| \leq p(\left|x\right|)$ for all $y\in S_x$ and 
			\item the language $\{(x,y)| x \in x \text{ and } y\in S_x\}$ is decidable in polynomial time
		\end{itemize}
	\item $c: \{(x,y)|x \in X \text{ and } y \in S_x\} \to \mathbb{Q}$ is computable in polynomial time. $c$ is a measurement of how good the approximated solution is.
	\item goal $\in \{\min, \max\}$
	\end{itemize}
	For $x \in X$ let OPT($x$) = goal$\{c(x,y)|y\in S_x\}$ where $\min \varnothing = \infty$ and $\max \varnothing = -\infty$ and $y \in S_x$ with $c(x,y) =$ OPT($x$) is an \underline{optimal solution} for $x$.\\
	\textbf{Definition}\\
	An algorithm $A$ for an optimization problem $P=(X,S_x,c,\text{goal})$ is a turing machine $\Phi$ with output($\Phi, x$) $\in S_x \; \forall x \in X$ with $S_x \neq \varnothing$. Let $A(x) = c(x,\text{output}(\Phi,x))$. If \[A(x) = \text{OPT}(x) \; \forall x \in X\] with $S_x \neq \varnothing$, then $A$ is an \underline{exact} algorithm. $A$ is an approximation with additive performance guarantee $k$, if \[\left|A(x) - \text{OPT}(x)\right| \leq k \; \forall x \in X \text{ and } S_x \neq \varnothing\] and a $k$-factor approximation algorithm, if \[\frac{1}{k}\cdot \text{OPT}(x) \leq A(x) \leq k\cdot\text{OPT}(x) \; \forall x \in X \text{ and } S_x \neq \varnothing\]
	\subsection{Examples}
	\underline{Comment}: For many problems, a \underline{greedy} approach yields a good approximation factor.\\
	\textbf{Problem} (Minimum Makespan / Job Scheduling with identical machines)\\
	INSTANCE: positive integers $\underbrace{n}_{\text{jobs}},\underbrace{m}_{\text{machines}},\underbrace{a_1,...,a_n}_{\text{required time for job $i$}}$\\

	\noindent GOAL: Determine a function $f: [n] \to [m]$ minimizing \[\max_{j \in [m]} a(f^{-1}(j)) = \max_{j \in [m]} \sum_{i \in [n] \; | \; f(i) = j} a_i\]
	
	\par\noindent\rule{\textwidth}{0.4pt}
	\noindent\underline{Greedy algorithm for job scheduling}:
	\begin{algorithmic}[1]
		\For{$i=1 \text{ to } n$}
			\State $f(i) \gets j, \text{ where $j$ minimizes } \sum_{l \in [i-1] | f(l) = j} a_l$
		\EndFor
		\State return $f$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}
	We can show, that this is a 2-factor algorithm\\
	Let $l \in [n]$ be the maximum such that $f(l) = k$, where $k \in [m]$ is the machine taking more time. When job $l$ was assigned to $k$ all $m$ machines had completion time at least $t = \sum_{l \in [i-1] | f(l) = k} a(f^{-1}(k))-a_l$ which implies that $a(f^{-1}(k)) = t+a_l \leq 2\cdot\text{OPT}(x)$.
	
	\subsection{Online and Offline Algorithms}
	\textbf{Definition}\\
	An algorithm is called \underline{online} if the input in only partially known before making decisions. I.e. a sequence $a_1,...,a_n$ is given and the decision for $a_{i-1}$ is made before knowing $a_i$. An example is Graham's algorithm for job scheduling.\\
	
	Consider the bin packing problem which is the dual problem of job scheduling. We will give an \underline{offline} algorithm for this optimization problem.\\
	\textbf{Problem} (bin packing)\\
	INSTANCE: $n \in \mathbb{N}$ and $a_1,...,a_n \in \mathbb{Q} \cap [0,1]$\\
	GOAL: Determine the minimal $k \in \mathbb{N}$ and a function \[f: [n] \to [k] \text{ s.t. } a(f^{-1}(j)) = \sum_{i \in [n], f(i) = j} a_i \leq 1 \; \forall j \in [k]\]
	\par\noindent\rule{\textwidth}{0.4pt}
	\underline{First Fit decreasing algorithm}\\
	INPUT $I = (a_1,...,a_n)$
	\begin{algorithmic}[1]
		\State $I \gets I'$ where $I'$ is sorted in a non-increasing way
		\For{$i=1$ to $n$}
			\State $f(j) \gets \min_j ((\sum_{l \in [i-1], f(l) = j} a_l) + a_i \leq 1)$
		\EndFor
		\State return $k,f$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}
	
	This algorithm puts any given element in the first bin, where the item fits. Therefore, the minimum $j$ is chosen, such that the sum if all items in the $j$-th bin is smaller than one.\\
	\textbf{Theorem}\\
	For a given instance $I$, we have $k \leq \lfloor \frac{3}{2} OPT(I) \rfloor$.\\
	\textbf{Proof}\\
	Let $j = \lceil \frac{2k}{3} \rceil$. Lets call an item $i$ with $a_i > \frac{1}{2}$ big and small otherwise. If bin $m$ has a big item, obviously all bins before $m$ will have a big item as well. Therefore \[OPT(I) \geq j = \lceil \frac{2k}{3} \rceil\] since no two big items can fit in the same bin. Now consider the first bin $l$ with no big items. That is to say, all bins before $l$ have a big item. It follows that bins $l$ to $k$ have only small items and $l$ to $k-1$ pack at least two items. So, $l < \frac{2k+2}{3}$ and then $l-1 \leq 2(k-l)+1$. It follows $OPT(I) \geq a_1 + \dots + a_n > l-1 = \lfloor \frac{2k}{3} + 1\rfloor$.\\
	
	\noindent\textbf{Problem} (3 dimensional matching)\\
	This problem is \textbf{NPC}.\\
	INSTANCE: three disjoint sets $U, V$ and $W$ of equal cardinality and a subset $T \subseteq U\times V \times W$ with $\left|T\right| \geq \left|U\right|$.\\
	GOAL: Decide whether there is a subset $S\subseteq T$ of order $\left|U\right|$ s.t. the elements of $S$ are pairwise different in all components.\\
	\textbf{Theorem}\\
	\texttt{3 Dimensional Matching} is \textbf{NP complete}.\\
	\textbf{Theorem}\\
	The \texttt{Subset Sum problem} is \textbf{NPC}.

	\section{Greedy Algorithms and Covering Problems}
	\subsection{Feedback Vertex Set}
	INPUT: a graph $G$ and a cost function $c: V(G) \to \mathbb{Q}_{>0}$\\
	GOAL: Determine a set $F$ of vertices of $G$ s.t. $G-F$ is a forest and $c(F) = \sum_{u \in F} c(u)$ is minimum.\\
	
	A set $F$ of vertices of a graph $G$ s.t. $G-F$ is a forest is a \underline{feedback vertex set}. \texttt{Feedback Vertex Set} is a special case of \texttt{Set Cover} where \begin{itemize}
		\item $U$ is the set of all cycles of $G$
		\item $\forall u \in G$ the (mulit-)set $S$ contains all cycles of $G$ that contain $u$
	\end{itemize}
	For a graph $G$ the \underline{cycle space} of $G$ is the subspace of $\mathbb{Z}_2^{E(G)}$ generated by the incidence vectors of cycles of $G$.\\
	\textbf{Claim}\\
	The dimension of the cycle space of $G$ is the \underline{cyclomatic number} \[\mu(G) = m(G) - n(G) + \kappa(G)\] where $\kappa(G)$ is the number of components of $G$.\\
	
	For any $u \in V(G)$ let \[\delta_{\mu_G} (u) = \mu(G) - \mu(G-u)\]
	If $H$ is a subgraph and $u \in V(H)$, then $\delta_{\mu_H}(u) \leq \delta_{\mu_G}(u)$. Therefore, if $F$ is a feedback vertex set, we have $\mu(G) \leq \sum_{u \in F}\delta_{\mu_G}(u)$.\\
	\textbf{Lemma}\\
	If $F$ is a minimal feedback vertex set of some $G$, then \[\sum_{u \in F} \delta_{\mu_G}(u) \leq 2\cdot \mu(G)\]
	\par\noindent\rule{\textwidth}{0.4pt}
	\underline{Algorithm}\\
	INPUT: An instance $(G,c)$ of \texttt{Feedback Vertex Set}\\
	OUTPUT: A feedback vertex set $F$
	\begin{algorithmic}[1]
		\State $G_0 \gets G; c' \gets c; i \gets 0$
		\While{$\mu(G_i) > 0$}
		\State $\varepsilon \gets \min\{\frac{c'(u)}{\delta_{\mu_{G_i}}(u)}: u \in V(G_i)$ and $\delta_{\mu_{G_i}}(u) > 0\}$
		\If{$u \in V(G_i)$}
		\State $c_i(u) \gets \varepsilon \cdot \delta_{\mu_{G_i}}(u)$
		\Else
		\State $c_i(u) \gets 0$
		\EndIf
	\State $c' \gets c' - c_i;\; G_{i+1} \gets G_i[\{u \in V(G_i): c'(u) > 0\}];\; i \gets i+1$
	\EndWhile
	\State $k \gets i;\; c_k \gets c';\; F_k \gets \emptyset$
	\For{$i$ \textbf{from} $k$ \textbf{down to} $1$}
	\State Extend the feedback vertex set $F_i$ of $G_i$ to a feedback vertex set $F_{i-1}$ of $G_{i-1}$ by \indent adding a minimal set of vertices from $V(G_{i-1})\setminus V(G_i)$
	\EndFor
	\State \textbf{return} $F_0$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	
	\noindent\textbf{Theorem}\\
	Above algorithm is a polynomial time 2-factor approximation for \texttt{Feedback Vertex Set}.
	\subsection{Maximum Satisfiability}
	\textbf{Definition} (\texttt{Maximum Satisfiability})\\
	INSTANCE: A set $X$ of variables, a set $\mathcal{C}$ of clauses over $X$ and a function $c: \mathcal{C} \to \mathbb{Q}_{>0}$\\
	GOAL: Find a truth assignment $t$ maximizing the total weight  \[\sum_{C \in \mathcal{C}: C \text{ true under } t} c(C)\]
	of satisfied clauses. \texttt{Maximum Satisfiability} is \textbf{NP hard}. $\mathcal{C}$ is a yes-instance of SAT iff the optimum value of \texttt{Maximum Satisfiability} for $\mathcal{C}$ equals the total weight of all clauses.\\
	\textbf{Comment} (Method of conditional expectation)\\
	Let $(X,\mathcal{C},c)$ be an instance of \texttt{Maximum Satisfiability}. if $t$ is a random truth assignment for $X$, we get the expected value by \[\mathbb{E}[T] = \sum_{j \in [m]} c(C_j)\cdot \mathbb{P}(C_j \text{ true under } t)\]
	where $T$ is the random variable that describes the true assignments of $t$. In order to obtain a deterministic approximation algorithm, we apply the \underline{method of conditional expectation}.\\
	For $p_1,...,p_n \in [0,1]$ let \[c(t(x_1),...,t(x_i),r(p_{i+1}),...,r(p_n)) = \mathbb{E}[\text{total weight of satisfied clauses}]\]
	where \begin{itemize}
		\item the truth values $t(x_1),...,t(x_i)$ are fixed and 
		\item the remaining $n-i$ truth assignments are chosen randomly. 
	\end{itemize}
	Note that \[c(t(x_1),...,t(x_i),r(p_{i+1}),...,r(p_n)\]
	equals \begin{align*}
		p_i &\cdot c(t(x_1),...,t(x_{i-1}), true,r(p_{i+1}),...,r(p_n))\\ + (1-p_i)&\cdot c(t(x_1),...,t(x_{i-1}),false,r(p_{i+1}),...,r(p_n))\\
		&\leq \max \{c(t(x_1),...,t(x_{i-1}), true,r(p_{i+1}),...,r(p_n)),\\ &c(t(x_1),...,t(x_{i-1}),false,r(p_{i+1}),...,r(p_n))\}
	\end{align*}

	\par\noindent\rule{\textwidth}{0.4pt}
	\underline{Johnson's algorithm}\\
	INPUT: An instance $(x,\mathcal{C}, c)$ of \texttt{maximum satisfiability}\\
	OUTPUT: $t: X \to \{\text{true, false}\}$
	\begin{algorithmic}[1]
		\For{$i=1$ to $n$}
		\If{$c(t(x_1),...,t(x_{i-1}), true,r(p_{i+1}),...,r(p_n)) \geq c(t(x_1),...,t(x_{i-1}),false,r(p_{i+1}),...,r(p_n))$}
		\State $t(x_i) \gets$ true
		\Else
		\State $t(x_i) \gets$ false
		\EndIf
		\EndFor
		\State \textbf{return} $t$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	\textbf{Theorem}\\
	For a given instance of \texttt{Maximum Satisfiability} the above algorithm determines a truth assignment $t$ with \[\sum_{C \in \mathcal{C}: C \text{ true under } t} c(C) \geq \frac{1}{2} OPT(X,\mathcal{C},c)\]
	\textbf{Comment} (integer linear program for \texttt{Maximum Satisfiability})\\
	The problem can also be solved using an integer linear program. This yields another algorithm which we analyse in the following. 
	\par\noindent\rule{\textwidth}{0.4pt}
	\underline{Goemans-Williamson's algorithm}\\
	INPUT: An instance $(x,\mathcal{C}, c)$ of \texttt{maximum satisfiability}\\
	OUTPUT: $t: X \to \{\text{true, false}\}$
	\begin{algorithmic}[1]
		\State Let $(t_1,...,t_n) \in [0,1]^n$ be the value from an optimal solution of (P).
		\For{$i=1$ to $n$}
		\If{$c(t(x_1),...,t(x_{i-1}), true,r(t_{i+1}),...,r(t_n)) \geq c(t(x_1),...,t(x_{i-1}),false,r(t_{i+1}),...,r(t_n))$}
		\State $t(x_i) \gets$ true
		\Else
		\State $t(x_i) \gets$ false
		\EndIf
		\EndFor
		\State \textbf{return} $t$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	\textbf{Theorem}\\
	For a given instance of \texttt{Maximum Satisfiability} the above algorithm determines a truth assignment $t$ with \[\sum_{C \in \mathcal{C}: C \text{ true under } t} c(C) \geq \left(1-\frac{1}{\varepsilon}\right)\cdot OPT(X,\mathcal{C},c)\]
	where $1-\frac{1}{\varepsilon} \geq 0.63$.\\
	\textbf{Theorem}\\
	If one combines both algorithm for a given instance, a $\frac{4}{3}$ factor approximation can always be achieved by choosing the better result.
	\subsection{Knapsack}
	\textbf{Definition}\\
	INSTANCE: positive integers $n, c_1,...,c_,.w_1,...,w_n,W$ with $\sum_{j \in [n]} w_j > W$ and $w_j \leq W$.\\
	GOAL: Determine a set $S \subset [n]$ with $\sum_{i \in S} w_i \leq W$ such that $\sum_{i \in S} c_i$ is maximized.\\
	
	This problem can be easily described as an integer linear program: \begin{align*}
		\max &\sum_{i\in [n]} c_i x_i\\
		\text{s.t. } &\sum_{i\in [n]} w_i x_i \leq W\\
		&x_i \in \{0,1\}
	\end{align*}
	Relaxing this by replacing $x_i \in \{0,1\}$ with $x_i \in [0,1]$ yields a simpler linear program $(P)$.\\
	\textbf{Claim}: If \[\frac{c_1}{w_1} \geq ... \geq \frac{c_n}{w_n}\]
	and \[i^* = \min \{i \in [n]: \sum_{j \in [i]} w_j \geq W\}\]
	then we can set \[x_i = \begin{cases}
		1, & 1 \leq i \leq i^*-1\\
		(W-\sum_{j \in [i^*-1]}w_j)/w_{i^*}, & i = i^*\\
		0, & i^*+1 \leq i \leq n
	\end{cases}\]
	and achieve an optimal solution to $(P)$. Note that \[x' = (\underbrace{1,...1}_{i^*-1},0,...,0) \text{ and } x'' = (\underbrace{0,...,0}_{i^*-1},1,0,...,0)\]
	are both feasible solutions for $(P_I)$ with $c^Tx \leq c^T(x'+x'')$, hence \[\max\{c^Tx',\; c^Tx''\} \geq \frac{1}{2} OPT(P) \geq \frac{1}{2} OPT(P_I)\] Therefore returning the better of the two solutions achieves a $2$-factor approximation algorithm. The problem is \textbf{NP}-hard.\\
	\textbf{Theorem}\\
	There is an exact algorithm for \texttt{Knapsack} with running time $\mathcal{O}(size(I)\cdot C)$ for an instance $I$ and an integer $C \geq OPT(I)$. Note that $\sum_{i\in [n]}c_i$ is a possible choice for $C$.\\
	\textbf{Comment}\\
	The following algorithm is an online algorithm that decides for each element based only on \begin{itemize}
		\item the values $c_i$ and $w_i$ of the current $i$-th item
		\item the currently available space
		\item the following global parameters of any instance $I$ \begin{itemize}
			\item[$\rightarrow$] $U = \max\{\frac{c_i}{w_i}: \; i \in [n]\}$
			\item[$\rightarrow$] $L = \min\{\frac{c_i}{w_i}: \; i \in [n]\}$ and 
			\item[$\rightarrow$] $\varepsilon = \max\{\frac{w_i}{W}: \; i \in [n]\}$.
		\end{itemize}
	\end{itemize}

	The decision is based on the function $\psi: [0,1] \to [0,U]$ that has the following attributes: \begin{itemize}
		\item $\psi(0) = \frac{L}{e}$
		\item $\psi(z_L) = L$
		\item $\psi(1) = U$
	\end{itemize}  
	The \underline{competitive ratio} of this algorithm is \[\left(\frac{Ue}{L}\right)^{2\varepsilon}\left(1+\ln\left(\frac{U}{L}\right)\right)\]
	which is basically the best possible. The competitive ratio is a measurement that describes how good the performance of an algorithm is compared to an optimal offline algorithm. The trivial online algorithm has a competitive ratio of \[\frac{U}{(1-\varepsilon)L}\] because any solution from this algorithm yields a value of at least $L(1-\varepsilon)$.
	\par\noindent\rule{\textwidth}{0.4pt}
	INPUT: An instance $(n,c_1,...,c_n, w_1,...,w_n,W)$ of \texttt{knapsack}\\
	Let $U,L,\varepsilon$ as above and $z_L = \frac{1}{1+\ln (\frac{U}{L})}$ and $\psi(z) = \begin{cases}
		L, & 0\leq z \leq z_L\\
		\frac{L}{e}(\frac{Ue}{L})^z, & z_L < z \leq 1
	\end{cases}$\\
	OUTPUT: A feasible solution $S \subseteq [n]$.
	\begin{algorithmic}[1]
		\State $S \gets \emptyset$
		\State $z_1 \gets 0$
		\For{$i=1$ to $n$}
		\If{$\frac{c_i}{w_i} \geq \psi(z_i)$ and $z_i + \frac{w_i}{W} \leq 1$}
		\State $S \gets S \cup \{i\}$
		\State $z_{i+1} \gets z_i + \frac{w_i}{W}$
		\Else
		\State $z_{i+1} \gets z_i$
		\EndIf
		\EndFor
		\State \textbf{return} $S$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	\textbf{Theorem}\\
	Above algorithm returns a feasible solution $S$ with \[OPT(I) \leq \left(\frac{Ue}{L}\right)^{2\varepsilon}\left(1+\ln \left(\frac{U}{L}\right)\right)c(S)\]
	\subsection{Facility Location Problem}
	\textbf{Definition}\\
	INSTANCE: two positive integers $m$ and $n$ and non-negative rationals $f_i$ and $a_{i,j}$ for $i \in [n]$ and $j \in [m]$.\\
	GOAL: determine a subset $X$ of $[n]$ and a function $\sigma: [m] \to X$ minimizing \[\sum_{i \in X} f_i + \sum_{j \in [m]} c_{\sigma(j),j}\]
	\begin{itemize}
		\item the term $\sum_{i \in X} f_i$ simulates the \underline{opening costs}
		\item the term $\sum_{j \in [m]} c_{\sigma(j),j}$ simulates the \underline{service costs}
	\end{itemize}
	Notice that for a given set $X$ which fixes the opening cost, it is easy to find a $\sigma$ that minimizes the service cost.\\
	\textbf{Theorem}\\
	\texttt{Dominating Set} can be reduced to \texttt{Facility Location}.
	\begin{itemize}
		\item $G$ has a \texttt{Dominating Set} of size at most $k$ iff 
		\item the optimal value for the instance of \texttt{Facility Location} with $m = n$, $f_i = 1$ for $i \in [n]$ and 
	\end{itemize}
	\[c_{i,j} = \begin{cases}
		0, & i = j\\
		0, & i	j \in E(G)\\
		k+1, & \text{else}
	\end{cases}\] for $i,j \in [n]$ is at most $k$.
	The problem can also be modelled as an integer linear program: \begin{align*}
		\min \sum f_i y_i + \sum_{i\in [n]}\sum_{j \in [m]} c_{i,j} x_{i,j}\\
		\text{s.t.} \sum_{i\in [n]}x_{i,j} \geq 1 \;\forall j \in [m]\\
		y_i - x_{i,j} \geq 0 \;\forall j \in [m]\\
		y_i, x_{i,j} \in \{0,1\} \;\forall i \in [n], j \in [m]
	\end{align*}
	\par\noindent\rule{\textwidth}{0.4pt}
	INPUT: An instance $I = (n,m,(f_i)_{i \in [n]}, (e_{i,j})_{i \in [n], j \in [m]})$ of \texttt{Metric Facility Location}.
	OUTPUT: A feasible solution $(X, \sigma)$.
	\begin{algorithmic}[1]
		\State Determine optimal solutions $(x^*, y^*)$ of the program $P$ and $(v^*, w^*)$ of its dual $D$
		\State $k \gets 0$, $X \gets \emptyset$, $R \gets [m]$
		\While{$R \neq \emptyset$}
		\State $k \gets k+1$
		\State Let $j_k \in R$ such that $v_{j_k}^*$ is minimum
		\State Let $i_k \in [n]$ with $x_{i_k,j_k}^* > 0$ be such that $f_{i_k}$ is minimum
		\State $X \gets X \cup \{i_k\}$
		\State $N_k \gets \{j \in R | \exists i \in [n] | x_{i,j_k}^* > 0 \text{ and } x_{i,j}^* > 0\}$
		\State $\sigma(j) \gets i_k \; \forall j \in N_k$
		\State $R \gets R \setminus N_k$
		\EndWhile
		\State return $(X, \sigma)$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	An instance of \texttt{Facility Location} is \texttt{Metric} if $c_{i,j}$ satisfies an inequality that corresponds to distances. \[c_{i,j} - c_{i',j} \leq c_{i,j'} + c_{i',j'}\]
	\textbf{Theorem}\\
	Above algorithm yields a $4$-factor approximation.\\
	\textbf{Comment} (\texttt{Set Cover})\\
	INSTANCE: A set system $(U,S)$ with $U = \bigcup_{s \in S} s$ and a weight function $c:S \to \mathbb{Q}_{>0}$.\\
	GOAL: Determine a subset $R \subseteq S$ with \[U = \bigcup_{s \in R} \text{ such that } c(R) = \sum_{s\in R} c(s) \text{ is minimum}\]
	A set $R$ with $U = \bigcup_{s \in R} s$ is a \underline{set cover}.\\
	
	\texttt{Set Cover} is \textbf{NP}-hard. One proof uses the fact that \begin{itemize}
		\item a graph $G$ has an independent set of order at least $k$
		\item iff $G$ has a \texttt{Vertex Cover} of order at most $n(G)-k$
		\item iff the \texttt{Set Cover} instance \[\left(E(G), \{\{uv: v \in N_G(u)\}: u \in V(G)\}, 1\right)\]
		has a \texttt{Set Cover} of order at most $n(G)-k$.
	\end{itemize} 
	\par\noindent\rule{\textwidth}{0.4pt}
	INPUT: An instance $(U,S,c)$ of \texttt{Set Cover}
	OUTPUT: A \texttt{Set Cover} $R$
	\begin{algorithmic}[1]
		\State $R \gets \emptyset$
		\State $W \gets \emptyset$
		\While{$W\neq U$}
		\State Choose $r \in S\setminus R$ minimizing $\frac{c(r)}{\left|r\setminus W\right|}$
		\State $R \gets R \cup \{r\}$
		\State $W \gets W \cup r$
		\EndWhile
		\State return $R$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	\textbf{Theorem}\\
	For a given instance $(U,S,c)$ of \texttt{Set Cover} can achieve a \[c(R) \leq H(r)\cdot OPT(U,S,c)\] approximation factor with \[r = \max\{\left|s\right|: s \in S\}\] and $H(r)$ the geometric sum \[H(r) = \sum_{i = 1}^{r} \frac{1}{i} \approx \ln(r)\]
	\subsection{Network Design}
	\textbf{Comment} (\texttt{Survivable Network Design})\\
	INSTANCE: A graph $G$, a function $c: E(G) \to \mathbb{Q}_{>0}$ and a function $r: \binom{V(G)}{2} \to \mathbb{Z}_{\geq 0}$.\\
	GOAL: Determine a spanning subgraph $H$ such that for every two distinct vertices $u$ and $v$ of $G$ the graph $H$ contains $r(u,v)$ edge-disjoint paths between $u$ and $v$ minimizing the cost $c(E(H))$ = $\sum_{e \in E(H)} c(e)$. If $r \equiv 1$, then a minimum spanning tree solves the problem.\\
	If $S \subseteq V(G)$ and \[r(u,v) = \begin{cases}
		1,& uv \in \binom{S}{2}\\
		0, & \text{otherwise}
	\end{cases}\]
	we obtain the following special case:\\
	\textbf{Comment} (\texttt{Steiner Tree})\\
	INSTANCE: Graph $G$, $c: E(G) \to \mathbb{Q}_{\geq 0}$ and a set $S \subseteq V(G)$.\\
	GOAL: Determine a connected subgraph $T$ of $G$ with $S \subseteq V(T)$ that minimizes $c(E(T))$ or proof that such a subgraph does not exist.\\
	
	Since $c \geq 0$, \texttt{Steiner Tree} always has an optimal solution that is a tree. \begin{itemize}
		\item any subgraph $T$ that is a tree with $S \subseteq V(T)$ is a \texttt{Steiner Tree}
		\item $S$ is also called a set of terminals
		\item $V(T)\setminus S$ are called the Steiner points.
	\end{itemize}
	Note that for $\left|S\right| = 2$ the problem is equivalent to the \texttt{Shortest Path} problem.\\
	\textbf{Theorem}\\
	\texttt{Steiner Tree} is \textbf{NP}-hard for instances $(G,c,S)$ with $c \equiv 1$.\\
	\textbf{Theorem}\\
	Let $G$ be a graph and $c: E(G) \to \mathbb{Q}_{\geq 0}$. For $U \subseteq V(G)$ and $x \in V(G) \setminus U$ let \begin{align*}
		p(U) &= \min \{c(E(T)): T \text{ is a \texttt{Steiner Tree} for $U$ in $G$}\}\\
		q(U\cup \{x\}, x) &= \min_{\emptyset \neq U' \neq U}\{p(U'\cup \{x\}) + p((U\setminus U')\cup \{x\})\}
	\end{align*}
	For $\left|U\right| \geq 2$, the term $p(U\cup \{x\})$ equals \[\min\{\min_{y \in U}\{p(U) + dist_{G,c}(x,y)\}, \min_{y \in V(G) \setminus U}\{q(U\cup \{y\}, y)\} + dist_{G,c}(x,y)\}\]
	\section{Multicommodity Flow}
	\textbf{Comment} (FPTAS)\\
	A \underline{fully polynomial time approximation scheme} is an algorithm that for a problem $P$ \begin{itemize}
		\item determines a feasible solution for $I$ with \[\frac{OPT(I)}{1+\varepsilon} \leq A(I,\varepsilon) \leq (1+\varepsilon)OPT(I)\]
		\item and has a polynomial running time.
	\end{itemize}
	\textbf{Comment}\\
	We consider the following generalization of the network flow problem:\\
	INSTANCE: $(D,D',c,b)$ where $D$ and $D'$ are digraphs with the same vertex set, $c:A(F) \to \mathbb{Q}_{\geq 0}$ is a capacity function and $b: A(D') \to \mathbb{Q}_{\geq 0}$ is a demand function.\\
	GOAL: Is there a family $(x^f)_{f \in A(D)}$ where for every $f = (t,s) \in A(D')$, $x^f$ is an $s-t-$flow of value $b(f)$ ind $D$ s.t. \[\sum_{f \in A(D')}x^f(e) \leq c(e)\] for every arc $e$ of $D$.\\
	We assume that $D$ and $D'$ may contain cycles of length 2 but no loops or multiple copies of the same arc.\\
	We can interpret this decision problem as a maximization problem:\\
	\texttt{Maximum Mulitcommodity Flow}\\
	INSTANCE: $(D,D',c)$ as before.\\
	GOAL: Determine a family $(^f)_{f \in A(D')}$ as before but maximize \[\sum_{f \in A(D')}b(f)\] where $b$ is not necessarily given.\\
	\texttt{Multicommodity Flow} is equivalent to the problem of deciding whether a system of linear inequalities has a solution. \texttt{Maximum Multicommodity Flow} is equivalent to a linear problem of polynomial size. Therefore, both problems are in \textbf{P}. The algorithms are theoretically efficient but there are simpler and faster combinatorial approximation algorithms.\\
	
	We now focus on the special case of the integer version of the problem: Let our instance be on an undirected integral weighted tree, therefore \begin{itemize}
		\item $T$ is a tree
		\item $c: E(T) \to \mathbb{Z}_{\geq 0}$
		\item $\{s_1t_1,...,s_kt_k\} \subseteq \binom{V(T)}{2}$ is a set of $k$ distinct unordered pairs of vertices of $T$. 
	\end{itemize} 
	For every $i \in [k]$ $T$ contains a unique $s_i-t_i$ path $P_i$, consider the following linear program: \begin{align*}
		&\max \sum_{i \in [k]} f_i\\
		\text{s.t.} &\sum_{i \in [k]: e \in E(P_i)} f_i \leq c(e) \;\forall e \in E(T)\\
		&f_i \geq 0 \;\forall i \in [k]
	\end{align*}
	The dual of this is \begin{align*}
		&\min \sum_{e \in E(T)} c(e)d_e\\
		\text{s.t.} &\sum_{e \in E(P_i)} d_e \geq 1 \; \forall i \in [k]\\
		&d_e \geq 0 \; \forall e \in E(T)
	\end{align*}
	Let $D_I$ be the restricted version of $D$ with $d_e \in \{0,1\}$. Then $D_I$ describes the problem to determine a cheapest set of edges of $T$ whose deletion separates all pairs $s_it_i$ with $i \in [k]$.\\
	A feasible solution is the incidence vector of a so-called \underline{multicut}, an optimal solution is a \underline{minimum multicut}.\\
	We now describe a duality-based approximation algorithm for the integral version of $(P)$ and $(D_I)$. By complementary slackness (,,komplementärer Schlupf'') feasible solutions of both problems iff the following hold: \begin{enumerate}
		\item $\forall e \in E(T): d_e > 0 \Rightarrow \sum_{i \in [k]: e \in E(P_i)} f_i = c(e)$ and 
		\item $\forall i \in [k]: f_i >0 \Rightarrow \sum_{e \in E(P_i)} d_e = 1$ which can be relaxed to
		\item $\forall i \in [k]: f_i>0 \Rightarrow \sum_{e \in E(P_i)} d_e \leq 2$
	\end{enumerate}
	Together with the weak duality we can guarantee \[\sum_{e \in E(T)} c(e)d_e \leq 2\cdot OPT(D) \text{ and } \sum_{i \in [k]} f_i \geq \frac{1}{2}\cdot OPT(P)\]
	Therefore, we can easily find a 2-factor approximation algorithm.\\
	\par\noindent\rule{\textwidth}{0.4pt}
	INPUT: $T$, $c$, and $\{s_1t_1,...,s_kt_k\}$\\
	OUTPUT: $(f_i)_{i\in[k]}$ and a multicut $C$
	\begin{algorithmic}[1]
		\State $f_i \gets 0$ for every $i \in [k]$; $C\gets \emptyset$
		\State Let $v_1,...,v_n$ be an ordering of $T$ not decreasing by depth
		\For{$j=1$ to $n$}
		\State Greedily increase $f_i$ in integer values for all $i \in [k]$ for which $v_j$ is the lowest common ancestor of $s_i$ and $t_i$ in $T$. Add all edges $e$ of $T$ to $C$ if they increase the result of \[\sum_{i \in [k]: e \in E(P_i)} f_i = c(e)\]
		\EndFor
		\State Let $e_1,...,e_l$ be an order in which the edges were added to $C$
		\For{$j = l$ down to 1}
		\If{$C\setminus \{e_j\}$ is a multicut}
		\State $C \gets C\setminus \{e_j\}$
		\EndIf
		\EndFor
		\State \textbf{return} $(f_i)_{i \in [k]}$, $C$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	\textbf{Lemma}\\
	Using above notation, $C$ contains at most one edge from the $v-s_i$-path $P$ and at most one edge from the $v-t_i$-path.\\
	\textbf{Theorem}\\
	Above algorithm returns a 2-factor approximation algorithm for \texttt{Multicommodity Flow} and its dual.\\
	\textbf{Lemma}\\
	If $f:A(D) \to \mathbb{R}_{\geq 0}$ is an $s-t$-flow of non-negative value $v$ in some digraph $D$, then there is \begin{itemize}
		\item a collection $\mathcal{P}$ of directed $s-t$-paths in $D$
		\item a collection $\mathcal{C}$ of directed cycles in $D$
		\item a function $w:\mathcal{P} \cup \mathcal{C} \to \mathbb{R}_{> 0}$ s.t. \begin{align*}
		f(e) &= \sum_{P \in \mathcal{P}\cup \mathcal{C}: e \in A(P)} w(P) \text{ for every arc $e$ of $D$}\\
		v &= \sum_{P \in \mathcal{P}}w(P)\\
		\left|\mathcal{P} \cup \mathcal{C}\right| &\leq \left|A(D)\right|
		\end{align*}
	\end{itemize}
	In particular, \[f': A(D) \to \mathbb{R}_{\geq 0} \text{ with } e\mapsto \sum_{P \in \mathcal{P}: e \in A(P)} w(P)\]
	is an $s-t$-flow of value $v$ in $D$ s.t. $f' \leq f$ and above decomposition uses paths in $\mathcal{P}$ only.\\
	\textbf{Theorem}\\
	Let $(D, D', c, b)$ be an instance of the \texttt{Multicommodity Flow}. Let \begin{itemize}
		\item $\mathcal{C}$ be the set of all directed cycles in the (not necessarily simple) digraph $D \cup D'$ that contain exactly one arc of $D'$. 
		\item $M$ be the the incidence matrix of the arcs of $D$ as rows and the cycles in $\mathcal{C}$ as columns.
		\item $N$ be the incidence matrix of the arcs of $D'$ versus the cycles in $\mathcal{C}$.
	\end{itemize}
	$(D,D',c,b)$ is a yes-instance iff the polyhedron \[\{y \in \mathbb{R}_{\geq 0}\}^\mathcal{C}: My \leq c \text{ and } Ny = b\] is non-empty.\\
	\textbf{Corollary}\\
	Let $(D,D',c,b)$ be an instance of \texttt{Multicommodity Flow}. It is a yes-instance iff \[\sum_{f = (t,s)\in A(D')} b(f)dist_(D,x)(s,t) \leq \sum_{e \in A(D)} c(e)z(e)\] for every $z: A(D) \to \mathbb{R}_{\geq 0}$.\\
	\textbf{Comment} (Linear Program for \texttt{Maximum Multicommodity Flow})\\
	Take an instance as above. Let $\mathcal{P}$ be the set of all directed paths in $D$ s.t. each $P \in \mathcal{P}$ is a directed $s-t$-path for some arc $(t,s)$ of $D'$. Now by the previous Lemma, \texttt{Maximum Multicommodity Flow} is equivalent to the following program: \begin{align*}
		\max &\sum_{P \in \mathcal{P}} y_P\\
		\text{s.t.} \sum_{P \in \mathcal{P}: e \in A(P)} y_P &\leq c(e) \; \forall e \in A(D)\\
		y_P &\geq 0 \; \forall P \in \mathcal{P}
	\end{align*}
	with its dual \begin{align*}
		\min &\sum_{e \in A(D)} c(e)z_e\\
		\text{s.t.} \sum_{e \in A(P)} z_e & \geq 1 \; \forall P \in \mathcal{P}\\
		z_e &\geq 0 \; \forall e \in A(D)
	\end{align*}
	Note that $\mathcal{P}$ can be of exponential size and that a feasible $\{0,1\}$-solution of the dual is the incidence vector of directed multicut.\\
	\par\noindent\rule{\textwidth}{0.4pt}
	\underline{Garg-Könemann-Algorithm}\\
	INPUT: an instance $(D,D',c)$ and a $0 < \varepsilon < \frac{1}{2}$\\
	OUTPUT: a feasible solution for the program $P$ encoded by a $\mathcal{P}' \subset \mathcal{P}$, non-negative $y_P$
	\begin{algorithmic}[1]
		\State $\delta \gets (1+\varepsilon)(n(1+\varepsilon))^{\lceil \frac{5}{\varepsilon}\rceil}$; $z_e \gets \delta$ for all $e \in A(D)$; $\mathcal{P}' \gets \emptyset$
		\While{$\alpha(z) = \min \{dist_{D,z}(s,t): (t,s) \in A(D')\}<1$}
		\State Let $P \in \mathcal{P}$ be s.t. $z(A(P)) = \alpha(z)$; $\gamma \gets \min \{c(e): e \in A(P)\}$
		\State $y_P \gets \begin{cases}
			y_P + \gamma, & P \in \mathcal{P}'\\
			\gamma&, P \notin \mathcal{P}'
		\end{cases}$
		\State $\mathcal{P}' \gets \mathcal{P}' \cup \{P\}$
		\State $z_e \gets \left(1+\frac{\varepsilon \gamma}{c(e)}\right)z_e$ for all $e \in A(P)$
		\EndWhile
		\State $\xi \gets \max \left\{\frac{\sum_{P \in \mathcal{P}': e \in A(P)}y_P}{c(e)}: e \in A(D)\right\}$; $y_P \gets \frac{y_P}{\xi}$ for every $P \in \mathcal{P}'$
		\State \textbf{return} $\mathcal{P}'$ and $(y_P)_{P \in \mathcal{P}'}$
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	\textbf{Theorem}\\
	The output of this algorithm encodes a \texttt{Multicommodity Flow} $(x^f)_{f \in A(D')}$ of total flow value at least $\frac{1}{1+\varepsilon}OPT(I)$ and runs in polynomial time in $size(I)$. Thus, it is an FPTAS. 
	\section{\texttt{Minimum Makespan} and \texttt{Bin Packing}}
	\textbf{Comment}\\
	Let $I = (n,m,(a_i)_{i \in [n]})$ be an instance of \texttt{Minimum Makespan}. Let \[LB = \max\left\{a_1,...,a_n, \left\lceil\frac{a_1+...+a_n}{m} \right\rceil\right\}\] the lower bound. We know $LB \leq OPT \leq 2\cdot LB$. For some rational $\varepsilon$ and an integer $t \in [LB, 2LB]$ we consider the instance $I' = (a_1',...,a_n')$ of \texttt{Bin Packing} with \[a_i' = \begin{cases}
		0, & \text{if } a_i < t\varepsilon\\
		\varepsilon(1+\varepsilon)^l, & \text{if } a_i \in [t\varepsilon(1+\varepsilon)^l, t\varepsilon(1+\varepsilon)^{l+1}] \text{ for some } l \in \mathbb{N}_0
	\end{cases}\]
	Clearly $a_i't \leq a_i$ and $a_i \leq a_i't(1+\varepsilon)$ whenever $a_i \geq t \varepsilon$. Also, $a_i \leq t$ and $\varepsilon(1+\varepsilon)^l \geq 1$ for $l \geq \log_{1+\varepsilon}(\frac{1}{\varepsilon})$. Thus \[\left|\{a_1',...,a_n'\}\right| \leq \log_{1+\varepsilon}(\frac{1}{\varepsilon})+2\]
	The instance $I'$ can be solved exactly in polynomial time!\\
	\textbf{Lemma}\\
	Let $\varepsilon >0$ and $K \in \mathbb{N}$ fixed. There is a polynomial-time algorithm that determines an optimal solution for a given instance $I$ of \texttt{Bin Packing} that satisfies $\min(a_i) \geq \varepsilon$ and $\left|\{a_1,...,a_n\}\right|\leq K$.
	\par\noindent\rule{\textwidth}{0.4pt}
	INPUT: $(I,t,\varepsilon)$ as in above Comment\\
	OUTPUT: An integer $\alpha(I,t,\varepsilon)$
	\begin{algorithmic}[1]
		\State Solve the \texttt{Bin Packing} instance $I'$ as in above Comment exactly. That is pack the items of sizes \[a_1't(1+\varepsilon),...,a_n't(1+\varepsilon)\]
		in the minimum number of bins of size $t(1+\varepsilon)$
		\State Assign every item $i$ with $a_i \geq t\varepsilon$ to the same bin as $a_i't(1+\varepsilon)$. Distribute the items $a_i < t\varepsilon$ to the existing and if necessary in new bins of same size.
		\State \textbf{return} the number of bins that is used
	\end{algorithmic}
	\par\noindent\rule{\textwidth}{0.4pt}\\
	\textbf{Lemma}\\
	Above algorithm has a polynomial running time and \[OPT\left(\frac{a_1}{(1+\varepsilon)t},...,\frac{a_n}{(1+\varepsilon)t}\right) \leq \alpha(I,t,\varepsilon) \leq OPT\left(\frac{a_1}{t},...,\frac{a_n}{t}\right)\]
	\textbf{Comment}\\
	By above Lemma and the Theorem of Graham we obtain \begin{align*}
		OPT(I) &= \min\left\{t \in \mathbb{N}: OPT\left(\frac{a_1}{t},...,\frac{a_n}{t}\right) \leq m\right\}\\
		& \geq \min\left\{t \in \mathbb{N}: t \geq LB \text{ and } \alpha(I,t,\varepsilon) \leq m\right\}
	\end{align*} and \begin{align*}
	\alpha(I, 2LB, \varepsilon) & \leq OPT\left(\frac{a_1}{2LB},...,\frac{a_n}{2LB}\right) \leq m
	\end{align*} which implies $\min\{t \in \mathbb{N}: t \geq LB \text{ and } \alpha(I,t,\varepsilon) \leq m\} \in [LB,2LB]$. Using binary search we determine an integer $T$ with $\min\{t \in \mathbb{N}: t \geq LB \text{ and } \alpha(I,t,\varepsilon) \leq m\} \in [T-\varepsilon LB, T]$ using $\mathcal{O}\left(\log \frac{1}{\varepsilon}\right)$ calls of above algorithm. Note that \[T \leq OPT(I)+\varepsilon LB \leq (1+\varepsilon) LB\]
	\textbf{Theorem}\\
	Let $\varepsilon$ be fixed. There is a polynomial time algorithm that, for a given instance $I$ of \texttt{Minimum Makespan} determines a feasible solution for $I$ whose objective function value is at most $(1+\varepsilon)^2OPT(I)$. That means there is a PTAS for \texttt{Minimum Makespan}.
	\section{Spreading Dynamics and Graph Convexities}
	\textbf{Definition}\\
	These are models for various types of spreading dynamics in networks such as opinions, viruses, etc. If for example the nodes $u$ and $v$ of a graph are infected, then under the model of the \underline{shortest path convexity} all nodes $w$ on the shortest path between $u$ and $v$ will be infected as well. Another example arises from the \underline{$P_3$ convexity} where every node that has two infected neighbours will be infected in the next step.
	
	\subsection{$P_3$-convexity}
	Using the last module, we define the \underline{$P_3$-convex hull}. Given a $S \subseteq V(G)$ we iteratively add vertices $v$ to $S$ if two neighbours of $v$ are in $S$. The set on which this process stabilizes is the convex hull.\\
	\textbf{Definition}\\
	$S$ is called a $P_3$-hull set if the $P_3$ convex hull equals $V(G)$. The $P_3$-hull number $h_{P_3}(G)$ is the size of a smallest $P_3$-hull set of $G$.\\
	In a \underline{$P_3$-interval set} $S$ of $G$ every vertex of $V(G)\setminus S$ has two neighbours in $S$. The $P_3$-interval number $i_{P_3}(G)$ is the cardinality of the smallest such set.
	
	\subsection{shortest-path-convexity}
	All definitions from the previous section also apply to the shortest-path-convexity strategy. The shortest-path-hull number $h_{sp}(G)$ and the shortest-path-interval number $i_{sp}(G)$ are defined as above.
	
	\subsection{NP-hardness}
	Each of the four parameters we just defined are \textbf{NP}-hard to determine on any given graph $G$ as input.
	
	\subsection{Different Graphs}
	\textbf{Definition}\\
	A \underline{unit interval graph} is a graph $G$ such that any induced cycle is a $C_3$.
	An \underline{$X$-free graph} is a graph that does not contain any \textit{induced} subgraph isomorphic to an element of $X$.\\
	The \underline{paw graph} arises from a $C_3$ by connecting one of the vertices with a fourth vertex.\\
	\textbf{Theorem}\\
	In the shortest-path convexity, the hull number of a given $\{\text{paw}, P_5\}$-free graph containing an induced $P_4$ graph can be computed efficiently.\\
	
	$h_{sp}(G)$ can be found in polynomial time for $P_4$-free graphs and for $\{\text{paw}, P_5\}$-free graphs but it is an open question for $P_L$-free graphs with $L \in \{5,6,7,8\}$. After that it is in \text{NPC}.
\end{document}